---
permalink: a1k/install-cable.html
sidebar: sidebar
keywords: aff a1k, prepare installation
summary: Management network ports on the controllers are connected to switches. The HA interconnect and cluster interconnect ports are cabled on both controllers. The controller modules are connected to external storage, if ordered.
---
= Cable the hardware - AFF A1K
:icons: font
:imagesdir: ../media/

[.lead]
After you install the rack hardware for your AFF A1K storage system, install the network cables for the controllers, and connect the cables between the controllers and storage shelves.


.Before you begin

Contact your network administrator for information about connecting the storage system to the switches.

.About this task
* These procedures show common configurations. The specific cabling depends on the components ordered for your storage system. For comprehensive configuration and slot priority details, see link:https://hwu.netapp.com[NetApp Hardware Universe^].

* The I/O slots on an AFF A1K controller are numbered 1 through 11.
+
image::../media/drw_a1K_back_slots_labeled_ieops-2162.svg[Slot numbering on an AFF A1K controller]

* The cabling graphics have arrow icons showing the proper orientation (up or down) of the cable connector pull-tab when inserting a connector into a port.
+
As you insert the connector, you should feel it click into place; if you do not feel it click, remove it, turn it over and try again.
+
image::../media/drw_cable_pull_tab_direction_ieops-1699.svg[Cable pull tab orientation example]

* If cabling to an optical switch, insert the optical transceiver into the controller port before cabling to the switch port.


== Step 1: Cable the cluster/HA connections
Cable the controllers to your ONTAP cluster. This procedure differs depending on your storage system model and I/O module configuration.

NOTE: The cluster interconnect traffic and the HA traffic share the same physical ports.

[role="tabbed-block"]
====

.Switchless cluster cabling
--
Use the Cluster/HA interconnect cable to connect ports e1a to e1a and ports e7a to e7a.

.Steps

. Connect port e1a on Controller A to port e1a on Controller B.
. Connect port e7a on Controller A to port e1a on Controller B.
+
*Cluster/HA interconnect cables*
+
image::../media/oie_cable_25Gb_Ethernet_SFP28_ieops-1069.png[Cluster HA cable]
+
image::../media/drw_a1k_tnsc_cluster_cabling_ieops-1648.svg[Two-node switchless cluster cabling diagram]


--
.Switched cluster cabling
--
Use the 100 GbE cable to connect ports e1a to e1a and ports e7a to e7a.

.Steps

. Connect port e1a on Controller A and port e1a on Controller B to cluster network switch A. 
. Connect port e7a on Controller A and port e7a on Controller B to cluster network switch B.
+
*100 GbE cable*
+
image::../media/oie_cable100_gbe_qsfp28.png[100 Gb cable]
+
image::../media/drw_a1k_switched_cluster_cabling_ieops-1652.svg[Cable cluster connections to cluster network]

--

====

== Step 2: Cable the host network connections
Connect the Ethernet module ports to your host network. 

The following are some typical host network cabling examples. See  link:https://hwu.netapp.com[NetApp Hardware Universe^] for your specific system configuration.

.Steps

. Connect ports e9a and e9b to your Ethernet data network switch.
+
// Issue ontap-systems/394 - Simplify statement previously here

NOTE: Do no use ports e1b and e7b ports for host network connections. Use a separate host card.

+
*100 GbE cable*
+
image::../media/oie_cable_sfp_gbe_copper.png[100Gb Ethernet cable]
+
image::../media/drw_a1k_network_cabling1_ieops-1649.svg[Cable to 100Gb Ethernet network]

+
. Connect your 10/25 GbE host network switches.
+
*10/25 GbE Host*
+
image::../media/oie_cable_sfp_gbe_copper.png[10/25Gb Ethernet cable]
+
image::../media/drw_a1k_network_cabling2_ieops-1650.svg[Cable to 10/25Gb Ethernet network]

== Step 3: Cable the management network connections
Use the 1000BASE-T RJ-45 cables to connect the management (wrench) ports on each controller to the management network switches.

*1000BASE-T RJ-45 cables*

image::../media/oie_cable_rj45.png[RJ-45 cables]


image::../media/drw_a1k_management_connection_ieops-1651.svg[Connect to your management network]

IMPORTANT: Do not plug in the power cords yet. 

== Step 4: Cable the shelf connections
The following cabling procedures show how to connect your controllers to a storage shelf. Choose one of the following cabling options that matches your setup.

For the maximum number of shelves supported for your storage system and for all of your cabling options, see link:https://hwu.netapp.com[NetApp Hardware Universe^].

.About this task

// Issue ontap-systems/350 - cover NSM100B

The AFF A1K storage systems support NS224 shelves with either the NSM100 or NSM100B module. The major differences between the modules are:  

** NSM100 shelf modules use built-in port e0a and e0b.

** NSM100B shelf modules use ports e1a and e1b in slot 1.

The following cabling example shows NSM100 modules in the NS224 shelves when referring to shelf module ports.

// start tabbed area

[role="tabbed-block"]
====

.Option 1: Connect to one NS224 storage shelf
--
Connect each controller to the NSM modules on the NS224 shelf. The graphics show controller A cabling in blue and controller B cabling in yellow.

*100 GbE QSFP28 copper cables*

image::../media/oie_cable100_gbe_qsfp28.png[100 GbE QSFP28 copper cable]

.Steps

. On controller A, connect the following ports:
.. Connect port e11a to NSM A port e0a.
.. Connect port e11b to port NSM B port e0b.
+
image:../media/drw_a1k_1shelf_cabling_a_ieops-1703.svg[Controller A e11a and e11b to a single NS224 shelf]

. On controller B, connect the following ports:
.. Connect port e11a to NSM B port e0a.
.. Connect port e11b to NSM A port e0b.
+
image:../media/drw_a1k_1shelf_cabling_b_ieops-1704.svg[Cable controller B ports e11a and e11b to a single NS224 shelf]

--

.Option 2: Connect to two NS224 storage shelves
--
Connect each controller to the NSM modules on both NS224 shelves. The graphics show controller A cabling in blue and controller B cabling in yellow.


*100 GbE QSFP28 copper cables*

image::../media/oie_cable100_gbe_qsfp28.png[100 GbE QSFP28 copper cable]

.Steps

. On controller A, connect the following ports:
.. Connect port e11a to shelf 1 NSM A port e0a.

.. Connect port e11b to shelf 2 NSM B port e0b.

.. Connect port e10a to shelf 2 NSM A port e0a.

.. Connect port e10b to shelf 1 NSM A port e0b.
+
image:../media/drw_a1k_2shelf_cabling_a_ieops-1705.svg[Controller-to-shelf connections for controller A]
+

. On controller B, connect the following ports:
.. Connect port e11a to shelf 1 NSM B port e0a.

.. Connect port e11b to shelf 2 NSM A port e0b.

.. Connect port e10a to shelf 2 NSM B port e0a.

.. Connect port e10b to shelf 1 NSM A port e0b.
+
image:../media/drw_a1k_2shelf_cabling_b_ieops-1706.svg[Controller-to-shelf connections for controller B]
+

--

====

// end tabbed area

.What's next?

After youâ€™ve cabled the hardware for your AFF A1K system, you link:install-power-hardware.html[power on the AFF A1K storage system].


